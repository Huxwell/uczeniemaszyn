{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systemy uczące się - laboratorium\n",
    "Filip Drapejkowski - nr indeksu: 2034050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ćwiczenie 1. Klasyfikator oparty na twierdzeniu Bayesa przy naiwnym założeniu o wzajemnej niezależności atrybutów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: podstawowe, techniczne operacje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rb\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.078, 21.0, 0.0]\n",
      "[17.0, 199.0, 122.0, 99.0, 846.0, 67.099999999999994, 2.4199999999999999, 81.0, 1.0]\n",
      "[17.0, 199.0, 122.0, 99.0, 846.0, 67.099999999999994, 2.3420000000000001, 60.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "dataset = loadCsv(filename)\n",
    "arr = np.asarray(dataset)\n",
    "arr_t = arr.transpose()\n",
    "mins = [min(attr) for attr in arr_t]\n",
    "maxes = [max(attr) for attr in arr_t]\n",
    "print mins\n",
    "print maxes\n",
    "ranges = [max - min for max,min in zip(maxes,mins)]\n",
    "print ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział na zbiór uczący i testowy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretize Wiktor\n",
    "def discretize_values(raw, n_parts=10):\n",
    "    max_v = []\n",
    "    min_v = []\n",
    "    diff_v = []\n",
    "    for values in zip(*[a[0] for a in raw]):\n",
    "        max_v.append(max(values))\n",
    "        min_v.append(min(values))\n",
    "        diff_v.append((max(values) - min(values)) / n_parts)\n",
    "\n",
    "    buckets = []\n",
    "    for ma, mi, di in zip(max_v, min_v, diff_v):\n",
    "        b=[]\n",
    "        for i in range(1, 1+n_parts):\n",
    "            b.append((mi+i*di, i))\n",
    "        buckets.append(b)\n",
    "    self.discretized = []\n",
    "    for pair in self.raw:\n",
    "        new_v = []\n",
    "        for value, b in zip(pair[0], buckets):\n",
    "            for threshold, tier in b:\n",
    "                if threshold > value:\n",
    "                    new_v.append(tier)\n",
    "                    break\n",
    "        self.discretized.append((new_v, pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(dataset):\n",
    "    #tutaj coś do [-1], bo [-1] to label class\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretize skoczylasa:\n",
    "@staticmethod\n",
    "    def _divide_and_count_into_buckets(buckets_num, feature_values, l, r):\n",
    "        discrete_feature_values = [0] * buckets_num\n",
    "        # l = min(feature_values)\n",
    "        # r = max(feature_values)\n",
    "        # step = (r - l) / buckets_num\n",
    "        discrete_index = 0\n",
    "        # for r_lim in range(l+step, r+step, step):\n",
    "        for x in feature_values:\n",
    "            v = TableClassifer._get_bucket(x, buckets_num, l, r)\n",
    "            discrete_feature_values[v] += 1\n",
    "        return discrete_feature_values, buckets_num, l, r\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_bucket(x, buckets_num, l, r):\n",
    "        v = float(x)\n",
    "        v -= l\n",
    "        v /= r - l\n",
    "        v *= buckets_num\n",
    "        v = int(v)\n",
    "        v = v % buckets_num\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowe wyjście funkcji:\n",
    "{0: [[2, 21, 0]], 1: [[1, 20, 1], [3, 22, 1]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateClasses(dataset): #KROK 1\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steps(separated):\n",
    "    #KROK 2:\n",
    "    j=1\n",
    "    #KROK 3:\n",
    "    for sublist in separated:\n",
    "        #podtablica np dla klasy 1\n",
    "    \n",
    "# KROK 2: Zainicjalizuj liczbę kombinacji atrybutów j jako j=1.\n",
    "#  KROK 3: Dla rozważanej podtablicy, podziel listę atrybutów\n",
    "# na odmienne kombinacje, każda kombinacja z j odmiennymi\n",
    "# atrybutami.\n",
    "#  KROK 4: Dla każdej kombinacji atrybutów, zlicz liczbę\n",
    "# wystąpień wartości atrybutu, które pojawiają się pod tą samą\n",
    "# kombinacją atrybutów w niezaznaczonych wierszach\n",
    "# rozważanej podtablicy, ale które w tym samym czasie nie\n",
    "# pojawiają się pod tą samą kombinacją atrybutów w innych\n",
    "# podtablicach. Nazwij pierwszą kombinację z maksymalną\n",
    "# liczbą wystąpień jako KOMBINACJA_MAKSYMALNA.\n",
    "#  KROK 5: Jeśli KOMBINACJA_MAKSYMALNA=0, zwiększ j o\n",
    "# 1 i przejdź do kroku 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiór danych - legenda \n",
    "\n",
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years) \n",
    "9. Class variable (0 or 1) - informacja, czy pacjent w ciągu 5 lat od dokonania pomiarów choruje na cukrzycę\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II: definicje funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries\n",
    "\n",
    "def summarizeClasses(dataset):\n",
    "    separated = separateClasses(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.iteritems():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries, inputVector):\n",
    "#     probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "#     bestLabel, bestProb = None, -1\n",
    "#     for classValue, probability in probabilities.iteritems():\n",
    "#         if bestLabel is None or probability > bestProb:\n",
    "#             bestProb = probability\n",
    "#             bestLabel = classValue\n",
    "    return predicted_class\n",
    "\n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III: Uczenie i testowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "splitRatio = 0.67\n",
    "dataset = loadCsv(filename)\n",
    "trainingSet, testSet = splitDataset(def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "dataset, splitRatio)\n",
    "print('Split {0} rows into train={1} and test={2} rows').format(len(dataset), len(trainingSet), len(testSet))\n",
    "# prepare model\n",
    "summaries = summarizeClasses(trainingSet)\n",
    "# test model\n",
    "predictions = getPredictions(summaries, testSet)\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print('Accuracy: {0}%').format(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykład:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print predict(summaries, [8,183,64,0,0,23.3,0.672,32,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV: Macierz błędu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prop](tablicapomylek.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 - średnia harmoniczna precyzji i czułości(recall) (poniżej dwie metody obliczania tej samej wartości)\n",
    "![f1](f1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictTable(dict):\n",
    "    # Overridden dict class which takes a dict in the form {'a': 2, 'b': 3},\n",
    "    # and renders an HTML Table in IPython Notebook.\n",
    "    def _repr_html_(self):\n",
    "        html = [\"<table width=100%>\"]\n",
    "        for key, value in self.iteritems():\n",
    "            html.append(\"<tr>\")\n",
    "            html.append(\"<td>{0}</td>\".format(key))\n",
    "            html.append(\"<td>{0}</td>\".format(value))\n",
    "            html.append(\"</tr>\")\n",
    "        html.append(\"</table>\")\n",
    "        return ''.join(html)\n",
    "def getTFCounts(testSet, predictions):\n",
    "    FP=0\n",
    "    TP=0\n",
    "    FN=0\n",
    "    TN=0\n",
    "    P = 0\n",
    "    N = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i] == 1:\n",
    "            TP += 1\n",
    "            P += 1\n",
    "        elif testSet[i][-1] == predictions[i] == 0:\n",
    "            TN += 1\n",
    "            N += 1\n",
    "        elif testSet[i][-1] != predictions[i] == 1:\n",
    "            FP += 1\n",
    "            P += 1\n",
    "        elif testSet[i][-1] != predictions[i] == 0:\n",
    "            FN += 1\n",
    "            N += 1\n",
    "    return[P,N,TP,TN,FP,FN]\n",
    "def getMetrics(P,N,TP,TN,FP,FN):\n",
    "    sensivity = float(TP) / (TP + FN)\n",
    "    specificity = float(TN) / N\n",
    "    precision = float(TP) / (TP + FP)\n",
    "    f1 = 2 * (precision * sensivity) / (precision + sensivity)\n",
    "    return(sensivity, specificity, precision, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = getTFCounts(testSet, predictions)\n",
    "metrics = getMetrics(*counts)\n",
    "print counts\n",
    "print metrics\n",
    "m = [('Czulosc',metrics[0]),('Specyficznosc',metrics[1]), ('Precyzja',metrics[2]), (u'f1',metrics[3])]\n",
    "m = dict(m)\n",
    "DictTable(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V: Walidacja krzyżowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "n_folds=10\n",
    "kf = KFold(len(dataset), n_folds=n_folds)\n",
    "results=[]\n",
    "for train_index, test_index in kf:\n",
    "    dataset = np.asarray(dataset)\n",
    "    trainingSet, testSet = dataset[train_index], dataset[test_index]\n",
    "    print('Podział {0} wierszy na ciąg_uczący o {1} wierszach i ciąg_testowy o {2} wierszach').format(len(dataset), len(trainingSet), len(testSet))\n",
    "    summaries = summarizeClasses(trainingSet)\n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    results.append(accuracy)\n",
    "    print('Dokładność: {0}%').format(accuracy)\n",
    "print results\n",
    "print('Średnia dokładność z walidacji krzyżowej o {0} złożeniach: {1}').format(n_folds,np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "n_folds=3\n",
    "kf = KFold(len(dataset), n_folds=n_folds)\n",
    "results=[]\n",
    "for train_index, test_index in kf:\n",
    "    dataset = np.asarray(dataset)\n",
    "    trainingSet, testSet = dataset[train_index], dataset[test_index]\n",
    "    print('Podział {0} wierszy na ciąg_uczący o {1} wierszach i ciąg_testowy o {2} wierszach').format(len(dataset), len(trainingSet), len(testSet))\n",
    "    summaries = summarizeClasses(trainingSet)\n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    results.append(accuracy)\n",
    "    print('Dokładność: {0}%').format(accuracy)\n",
    "print results\n",
    "print('Średnia dokładność z walidacji krzyżowej o {0} złożeniach: {1}').format(n_folds,np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestowawszy ilości złożeń takie jak: 2,3,5,10,50,100,200 stwierdzam, że dokładność oscylowała pomiędzy wartościami 73 a 75 bez monotonicznej zależności.\n",
    "\n",
    "Procedura walidacji krzyżowej ma na celu głównie przeciwdziałanie przeuczaniu (overfitting) podczas selekcji modelu (unikanie błędu 3ciego rodzaju).\n",
    "Można spodziewać się, że w przypadku wydzielenia 3ciego ciągu do testów, ukrytego na czas selekcji modelu użycie wielu złożeń powinno dawać lepsze wyniki. \n",
    "\n",
    "Zwyczajową ilością złożeń jest 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drugi zbiór danych - glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drugi zbiór danych - glass\n",
    "filename = 'glass.data.txt'\n",
    "splitRatio = 0.60\n",
    "dataset = loadCsv(filename)\n",
    "trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "print('Split {0} rows into train={1} and test={2} rows').format(len(dataset), len(trainingSet), len(testSet))\n",
    "# prepare model\n",
    "summaries = summarizeClasses(trainingSet)\n",
    "# test model\n",
    "predictions = getPredictions(summaries, testSet)\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print('Accuracy: {0}%').format(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI: Wnioski\n",
    "\n",
    "Naiwny klasyfikator bayesa jest łatwą w implementacji, szybką i dość skuteczną metodą klasyfikacji danych liniowo niezależnych.\n",
    "\n",
    "Niestety osiągane wyniki (dokładność do 75% zależnie od złożeń) nie są idealnie satysfakcjonujące.\n",
    "Wg autora wynika to z tego, że między danymi zachodzą zależności, których naiwny klasyfikator bayesa nie jest w stanie zauważyć.\n",
    "\n",
    "Być może redukcja wymiarów (np metodą PCA) umożliwyłaby uzyskanie lepszych wyników.\n",
    "Założenie pochodzenia danych z rozkładu normalnego powinno zostać dodatkowo zweryfikowane testami normalności (np testem Kołmogorowa - Smirnowa lub tesstem Shapiro - Wilka).\n",
    "Zasadne byłoby też zadbanie w przyszłości o zbalansowanie zbioru danych - tak, żeby każda klasa miała podobną ilość przykładów uczących.\n",
    "\n",
    "Co ciekawe, walidacja krzyżowa nie spowodowała znacznego spadku dokładności klasyfikacji (wyniki pomiędzy 75% a 73%), co wskazuje na poprawną zdolność generalizacji.\n",
    "\n",
    "Wg autora naiwny klasyfikator bayesowski, z uwagi na prostotę w implementacji i możliwość radzenia sobie z małą ilością przykładów może być bardzo skutecznie stosowany jako forma wspomagająca w innych metodach uczenia maszynowego.\n",
    "Np wydaje się być on dość dobry do szybkiego sortowania które wartości hiperparamterów sieci neuronowej bądź metody random forest warto przetestować najpierw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}