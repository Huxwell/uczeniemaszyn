{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systemy uczące się - laboratorium\n",
    "Filip Drapejkowski - nr indeksu: 2034050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ćwiczenie 1. Klasyfikator oparty na twierdzeniu Bayesa przy naiwnym założeniu o wzajemnej niezależności atrybutów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: podstawowe, techniczne operacje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rb\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział na zbiór uczący i testowy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowe wyjście funkcji:\n",
    "{0: [[2, 21, 0]], 1: [[1, 20, 1], [3, 22, 1]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separateClasses(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiór danych - legenda \n",
    "\n",
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years) \n",
    "9. Class variable (0 or 1) - informacja, czy pacjent w ciągu 5 lat od dokonania pomiarów choruje na cukrzycę\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II: definicje funkcji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Standard deviation](stdv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = 0 if float(len(numbers)-1) == 0.0 else sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries\n",
    "\n",
    "def summarizeClasses(dataset):\n",
    "    separated = separateClasses(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.iteritems():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prop](prop.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateProbability(x, mean, stdev):\n",
    "    if (2*math.pow(stdev,2)) == 0 return 0\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![prop](joint2.png)\n",
    "![prop](classify.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.iteritems():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.iteritems():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "\n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III: Uczenie i testowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 768 rows into train=514 and test=254 rows\n",
      "Accuracy: 78.7401574803%\n"
     ]
    }
   ],
   "source": [
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "splitRatio = 0.67\n",
    "dataset = loadCsv(filename)\n",
    "trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "print('Split {0} rows into train={1} and test={2} rows').format(len(dataset), len(trainingSet), len(testSet))\n",
    "# prepare model\n",
    "summaries = summarizeClasses(trainingSet)\n",
    "# test model\n",
    "predictions = getPredictions(summaries, testSet)\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print('Accuracy: {0}%').format(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykład:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print predict(summaries, [8,183,64,0,0,23.3,0.672,32,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV: Macierz błędu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prop](tablicapomylek.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 - średnia harmoniczna precyzji i czułości(recall) (poniżej dwie metody obliczania tej samej wartości)\n",
    "![f1](f1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DictTable(dict):\n",
    "    # Overridden dict class which takes a dict in the form {'a': 2, 'b': 3},\n",
    "    # and renders an HTML Table in IPython Notebook.\n",
    "    def _repr_html_(self):\n",
    "        html = [\"<table width=100%>\"]\n",
    "        for key, value in self.iteritems():\n",
    "            html.append(\"<tr>\")\n",
    "            html.append(\"<td>{0}</td>\".format(key))\n",
    "            html.append(\"<td>{0}</td>\".format(value))\n",
    "            html.append(\"</tr>\")\n",
    "        html.append(\"</table>\")\n",
    "        return ''.join(html)\n",
    "def getTFCounts(testSet, predictions):\n",
    "    FP=0\n",
    "    TP=0\n",
    "    FN=0\n",
    "    TN=0\n",
    "    P = 0\n",
    "    N = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i] == 1:\n",
    "            TP += 1\n",
    "            P += 1\n",
    "        elif testSet[i][-1] == predictions[i] == 0:\n",
    "            TN += 1\n",
    "            N += 1\n",
    "        elif testSet[i][-1] != predictions[i] == 1:\n",
    "            FP += 1\n",
    "            P += 1\n",
    "        elif testSet[i][-1] != predictions[i] == 0:\n",
    "            FN += 1\n",
    "            N += 1\n",
    "    return[P,N,TP,TN,FP,FN]\n",
    "def getMetrics(P,N,TP,TN,FP,FN):\n",
    "    sensivity = float(TP) / (TP + FN)\n",
    "    specificity = float(TN) / N\n",
    "    precision = float(TP) / (TP + FP)\n",
    "    f1 = 2 * (precision * sensivity) / (precision + sensivity)\n",
    "    return(sensivity, specificity, precision, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96, 158, 68, 132, 28, 26]\n",
      "(0.723404255319149, 0.8354430379746836, 0.7083333333333334, 0.7157894736842105)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width=100%><tr><td>Specyficznosc</td><td>0.835443037975</td></tr><tr><td>Precyzja</td><td>0.708333333333</td></tr><tr><td>Czulosc</td><td>0.723404255319</td></tr><tr><td>f1</td><td>0.715789473684</td></tr></table>"
      ],
      "text/plain": [
       "{'Czulosc': 0.723404255319149,\n",
       " 'Precyzja': 0.7083333333333334,\n",
       " 'Specyficznosc': 0.8354430379746836,\n",
       " u'f1': 0.7157894736842105}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = getTFCounts(testSet, predictions)\n",
    "metrics = getMetrics(*counts)\n",
    "print counts\n",
    "print metrics\n",
    "m = [('Czulosc',metrics[0]),('Specyficznosc',metrics[1]), ('Precyzja',metrics[2]), (u'f1',metrics[3])]\n",
    "m = dict(m)\n",
    "DictTable(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V: Walidacja krzyżowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podział 768 wierszy na ciąg_uczący o 691 wierszach i ciąg_testowy o 77 wierszach\n",
      "Dokładność: 70.1298701299%\n",
      "Podział 768 wierszy na ciąg_uczący o 691 wierszach i ciąg_testowy o 77 wierszach\n",
      "Dokładność: 79.2207792208%\n",
      "Podział 768 wierszy na ciąg_uczący o 691 wierszach i ciąg_testowy o 77 wierszach\n",
      "Dokładność: 71.4285714286%\n",
      "Podział 768 wierszy na ciąg_uczący o 691 wierszach i ciąg_testowy o 77 wierszach\n",
      "Dokładność: 66.2337662338%\n",
      "Podział 768 wierszy na ciąg_uczący o 691 wierszach i ciąg_testowy o 77 wierszach\n",
      "Dokładność: 74.025974026%\n",
      "Podział 768 wierszy na ciąg_uczący o 691 wierszach i ciąg_testowy o 77 wierszach\n",
      "Dokładność: 75.3246753247%\n",
      "Podział 768 wierszy na ciąg_uczący o 691 wierszach i ciąg_testowy o 77 wierszach\n",
      "Dokładność: 75.3246753247%\n",
      "Podział 768 wierszy na ciąg_uczący o 691 wierszach i ciąg_testowy o 77 wierszach\n",
      "Dokładność: 80.5194805195%\n",
      "Podział 768 wierszy na ciąg_uczący o 692 wierszach i ciąg_testowy o 76 wierszach\n",
      "Dokładność: 75.0%\n",
      "Podział 768 wierszy na ciąg_uczący o 692 wierszach i ciąg_testowy o 76 wierszach\n",
      "Dokładność: 76.3157894737%\n",
      "[70.12987012987013, 79.22077922077922, 71.42857142857143, 66.23376623376623, 74.02597402597402, 75.32467532467533, 75.32467532467533, 80.51948051948052, 75.0, 76.31578947368422]\n",
      "Średnia dokładność z walidacji krzyżowej o 10 złożeniach: 74.3523581681\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "n_folds=10\n",
    "kf = KFold(len(dataset), n_folds=n_folds)\n",
    "results=[]\n",
    "for train_index, test_index in kf:\n",
    "    dataset = np.asarray(dataset)\n",
    "    trainingSet, testSet = dataset[train_index], dataset[test_index]\n",
    "    print('Podział {0} wierszy na ciąg_uczący o {1} wierszach i ciąg_testowy o {2} wierszach').format(len(dataset), len(trainingSet), len(testSet))\n",
    "    summaries = summarizeClasses(trainingSet)\n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    results.append(accuracy)\n",
    "    print('Dokładność: {0}%').format(accuracy)\n",
    "print results\n",
    "print('Średnia dokładność z walidacji krzyżowej o {0} złożeniach: {1}').format(n_folds,np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podział 768 wierszy na ciąg_uczący o 512 wierszach i ciąg_testowy o 256 wierszach\n",
      "Dokładność: 73.828125%\n",
      "Podział 768 wierszy na ciąg_uczący o 512 wierszach i ciąg_testowy o 256 wierszach\n",
      "Dokładność: 68.359375%\n",
      "Podział 768 wierszy na ciąg_uczący o 512 wierszach i ciąg_testowy o 256 wierszach\n",
      "Dokładność: 76.953125%\n",
      "[73.828125, 68.359375, 76.953125]\n",
      "Średnia dokładność z walidacji krzyżowej o 3 złożeniach: 73.046875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "n_folds=3\n",
    "kf = KFold(len(dataset), n_folds=n_folds)\n",
    "results=[]\n",
    "for train_index, test_index in kf:\n",
    "    dataset = np.asarray(dataset)\n",
    "    trainingSet, testSet = dataset[train_index], dataset[test_index]\n",
    "    print('Podział {0} wierszy na ciąg_uczący o {1} wierszach i ciąg_testowy o {2} wierszach').format(len(dataset), len(trainingSet), len(testSet))\n",
    "    summaries = summarizeClasses(trainingSet)\n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    results.append(accuracy)\n",
    "    print('Dokładność: {0}%').format(accuracy)\n",
    "print results\n",
    "print('Średnia dokładność z walidacji krzyżowej o {0} złożeniach: {1}').format(n_folds,np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestowawszy ilości złożeń takie jak: 2,3,5,10,50,100,200 stwierdzam, że dokładność oscylowała pomiędzy wartościami 73 a 75 bez monotonicznej zależności.\n",
    "\n",
    "Procedura walidacji krzyżowej ma na celu głównie przeciwdziałanie przeuczaniu (overfitting) podczas selekcji modelu (unikanie błędu 3ciego rodzaju).\n",
    "Można spodziewać się, że w przypadku wydzielenia 3ciego ciągu do testów, ukrytego na czas selekcji modelu użycie wielu złożeń powinno dawać lepsze wyniki. \n",
    "\n",
    "Zwyczajową ilością złożeń jest 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI: Wnioski\n",
    "\n",
    "Naiwny klasyfikator bayesa jest łatwą w implementacji, szybką i dość skuteczną metodą klasyfikacji danych liniowo niezależnych.\n",
    "\n",
    "Niestety osiągane wyniki (dokładność do 75% zależnie od złożeń) nie są idealnie satysfakcjonujące.\n",
    "Wg autora wynika to z tego, że między danymi zachodzą zależności, których naiwny klasyfikator bayesa nie jest w stanie zauważyć.\n",
    "\n",
    "Być może redukcja wymiarów (np metodą PCA) umożliwyłaby uzyskanie lepszych wyników.\n",
    "Założenie pochodzenia danych z rozkładu normalnego powinno zostać dodatkowo zweryfikowane testami normalności (np testem Kołmogorowa - Smirnowa lub tesstem Shapiro - Wilka).\n",
    "Zasadne byłoby też zadbanie w przyszłości o zbalansowanie zbioru danych - tak, żeby każda klasa miała podobną ilość przykładów uczących.\n",
    "\n",
    "Co ciekawe, walidacja krzyżowa nie spowodowała znacznego spadku dokładności klasyfikacji (wyniki pomiędzy 75% a 73%), co wskazuje na poprawną zdolność generalizacji.\n",
    "\n",
    "Wg autora naiwny klasyfikator bayesowski, z uwagi na prostotę w implementacji i możliwość radzenia sobie z małą ilością przykładów może być bardzo skutecznie stosowany jako forma wspomagająca w innych metodach uczenia maszynowego.\n",
    "Np wydaje się być on dość dobry do szybkiego sortowania które wartości hiperparamterów sieci neuronowej bądź metody random forest warto przetestować najpierw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 214 rows into train=128 and test=86 rows\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-b70aa2c7b50f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummarizeClasses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# test model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetPredictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy: {0}%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-1e12c6a8a9f6>\u001b[0m in \u001b[0;36mgetPredictions\u001b[1;34m(summaries, testSet)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-1e12c6a8a9f6>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(summaries, inputVector)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputVector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprobabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculateClassProbabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputVector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mbestLabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestProb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mclassValue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobability\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbestLabel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprobability\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbestProb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-126c010860fc>\u001b[0m in \u001b[0;36mcalculateClassProbabilities\u001b[1;34m(summaries, inputVector)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassSummaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputVector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mprobabilities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassValue\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcalculateProbability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-45b9e1ef373f>\u001b[0m in \u001b[0;36mcalculateProbability\u001b[1;34m(x, mean, stdev)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculateProbability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mexponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstdev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mexponent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# Drugi zbiór danych\n",
    "filename = 'glass.data.txt'\n",
    "splitRatio = 0.60\n",
    "dataset = loadCsv(filename)\n",
    "trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "print('Split {0} rows into train={1} and test={2} rows').format(len(dataset), len(trainingSet), len(testSet))\n",
    "# prepare model\n",
    "summaries = summarizeClasses(trainingSet)\n",
    "# test model\n",
    "predictions = getPredictions(summaries, testSet)\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print('Accuracy: {0}%').format(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
